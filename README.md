# Attention_Classification
* 1. LSTM-attention 是在lstm的输出上使用attention机制
* 2. self-attention 是修改Tranformer的源码，只利用其中Encoder部分来进行序列分类
* 3. [分词文件和word2vec的词向量模型可以通过这个程序得到](https://github.com/huangqianfei0916/Fasta2svm/tree/master/Fasta2svm-1.0)
* 4. 3步骤主要是对数据进行分词，可以不用完全将3中model跑完，得到分词文件和词向量model就可以了；
